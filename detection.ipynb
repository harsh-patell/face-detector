{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9132609d-1d1e-4d53-8532-411dbc29e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf043d4-7ebe-4774-859e-b63d5b55aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join('data', 'images')\n",
    "num_pics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8350292-4cfd-4557-a66f-f442fbb8ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Gathering Data (pictures of myself)\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(num_pics):\n",
    "    ret_val, image = camera.read()\n",
    "    imgname = os.path.join(images_path, 'o' + str(uuid.uuid1()) + '.jpg')\n",
    "    cv2.imwrite(imgname, image)\n",
    "    cv2.imshow('image', image)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf330b-01e3-41b4-8b95-eae00d0579fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Image From Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92fb0bc-9bb9-4839-9a21-2178d36fa293",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 12:45:45.247686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fba99a4d-e8e1-4c93-bfd9-4f6ded1ab17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Parition Unaugmented Data - 70 train, 15 test, 15 val\n",
    "# Move matching labels (images done manually)\n",
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        label_file = file.split('.')[0]+'.json'\n",
    "        existing_path = os.path.join('data','labels', label_file)\n",
    "        if os.path.exists(existing_path): \n",
    "            new_path = os.path.join('data',folder,'labels',label_file)\n",
    "            os.replace(existing_path, new_path)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ad6c58-ba19-4f5e-bc8d-a18fb385e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Image Augmentation on Images + Labels\n",
    "import albumentations as alb\n",
    "\n",
    "# Create augmentation pipeline\n",
    "transform = alb.Compose([\n",
    "    alb.RandomCrop(width=450, height=450),\n",
    "    alb.HorizontalFlip(p=0.5),\n",
    "    alb.RandomBrightnessContrast(p=0.2),\n",
    "    alb.RandomGamma(p=0.2),\n",
    "    alb.RGBShift(p=0.2),\n",
    "    alb.VerticalFlip(p=0.5),\n",
    "], bbox_params=alb.BboxParams(format='albumentations', label_fields=['class_labels']))\n",
    "\n",
    "data_types = ['train', 'test', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba102a68-c5cb-4eef-aa4f-272b5c8037b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae598b1e-84fc-4225-a862-946d9a5c69a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('data', 'train', 'images','oa7b92f4e-73a4-11ee-bc9d-faffc22fdfb0.jpg'))\n",
    "# print(img.shape)\n",
    "h = img.shape[0]\n",
    "w = img.shape[1]\n",
    "\n",
    "with open(os.path.join('data', 'train', 'labels', 'oa7b92f4e-73a4-11ee-bc9d-faffc22fdfb0.json'), 'r') as label_file:\n",
    "    label = json.load(label_file)\n",
    "\n",
    "print(label) # label is a dictionary\n",
    "\n",
    "# Extract and transform coordinates into albumentations format\n",
    "coords = [0 for i in range(4)]\n",
    "coords[0] = label['shapes'][0]['points'][0][0] # x1\n",
    "coords[1] = label['shapes'][0]['points'][0][1] # y1\n",
    "coords[2] = label['shapes'][0]['points'][1][0] # x2\n",
    "coords[3] = label['shapes'][0]['points'][1][1] # y2\n",
    "print(coords)\n",
    "\n",
    "coords = list(np.divide(coords, [w, h, w, h]))\n",
    "print(coords) # albumentations format\n",
    "\n",
    "# Augment image\n",
    "augmented = transform(image=img, bboxes=[coords], class_labels=['face'])\n",
    "cv2.imwrite(os.path.join('aug_data', 'test', 'images', 'oa7b92f4e-73a4-11ee-bc9d-faffc22fdfb0.jpg'), augmented['image'])\n",
    "print(augmented.keys())\n",
    "\n",
    "# Show image\n",
    "cv2.rectangle(augmented['image'],\n",
    "              tuple(np.multiply(augmented['bboxes'][0][:2], [450, 450]).astype(int)),\n",
    "              tuple(np.multiply(augmented['bboxes'][0][2:], [450, 450]).astype(int)),\n",
    "              (255, 0, 0), 2)\n",
    "\n",
    "# plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6eba1d-42ed-4d10-8316-4c300402c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Create Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2275586-d6f6-4a79-b76c-8bd38ace5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in ['train','test','val']:\n",
    "    for image in os.listdir(os.path.join('data', type, 'images')):\n",
    "        \n",
    "        img = cv2.imread(os.path.join('data', type, 'images', image))\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "        coords = [0,0,0.00001,0.00001] # deafult coords (near 0) if label does not exist\n",
    "        label_path = os.path.join('data', type, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as label_file:\n",
    "                label = json.load(label_file)\n",
    "\n",
    "        coords[0] = label['shapes'][0]['points'][0][0] # x1\n",
    "        coords[1] = label['shapes'][0]['points'][0][1] # y1\n",
    "        coords[2] = label['shapes'][0]['points'][1][0] # x2\n",
    "        coords[3] = label['shapes'][0]['points'][1][1] # y2\n",
    "        \n",
    "        coords = list(np.divide(coords, [w, h, w, h])) # put coords in albumentations format\n",
    "\n",
    "        try: \n",
    "            for i in range(60):\n",
    "                augmented = transform(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', type, 'images', f'{image.split(\".\")[0]}.{i}.jpg'), augmented['image'])\n",
    "\n",
    "                aug_label_data = {}\n",
    "                aug_label_data['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: # no bounding box in the augmented image\n",
    "                        aug_label_data['bbox'] = [0, 0, 0, 0]\n",
    "                        aug_label_data['class'] = 0\n",
    "                    else:\n",
    "                        aug_label_data['bbox'] = augmented['bboxes'][0]\n",
    "                        aug_label_data['class'] = 1\n",
    "                else:\n",
    "                    aug_label_data['bbox'] = [0, 0, 0, 0]\n",
    "                    aug_label_data['class'] = 0\n",
    "\n",
    "                with open(os.path.join('aug_data', type, 'labels', f'{image.split(\".\")[0]}.{i}.json'), 'w') as aug_label_file:\n",
    "                    json.dump(aug_label_data, aug_label_file)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0f24d-6ea0-47dc-ad67-971bcb3e63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.a Load augmented Images to TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8af7910-635d-4ca0-b978-7a42350bacbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test', 'val'])\n"
     ]
    }
   ],
   "source": [
    "def load_image(file):\n",
    "    encoded = tf.io.read_file(file)\n",
    "    img = tf.io.decode_jpeg(encoded)\n",
    "    return img\n",
    "\n",
    "aug_images = {}\n",
    "for type in data_types:\n",
    "    type_images = tf.data.Dataset.list_files(f'aug_data/{type}/images/*.jpg', shuffle=False)\n",
    "    type_images = type_images.map(load_image)\n",
    "    type_images = type_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "    type_images = type_images.map(lambda x: x/255)\n",
    "    aug_images[type] = type_images\n",
    "print(aug_images.keys())\n",
    "# aug_images['test'].as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a86a8-139f-443b-9dae-345d30378917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.b Load augmented labels to TF Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2111746d-9d1a-4ac8-afd1-e0c3e9c78242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test', 'val'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=uint8), array([0., 0., 0., 0.], dtype=float16))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_labels(file): # understand more\n",
    "    with open(file.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']\n",
    "\n",
    "\n",
    "aug_labels = {}\n",
    "for type in data_types:\n",
    "    type_labels = tf.data.Dataset.list_files(f'aug_data/{type}/labels/*.json', shuffle=False)\n",
    "    type_labels = type_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16])) \n",
    "    aug_labels[type] = type_labels\n",
    "print(aug_labels.keys())\n",
    "aug_labels['train'].as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad734f0d-2548-47e4-992e-d137b3e0ef3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 4200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_images['train']), len(aug_labels['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f055b8a-d28d-4760-8784-a3f958104f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.82052696 0.76954657 0.703799  ]\n",
      "   [0.81666666 0.7656863  0.6990196 ]\n",
      "   [0.82941175 0.77843136 0.7117647 ]\n",
      "   ...\n",
      "   [0.69803923 0.654902   0.58431375]\n",
      "   [0.69803923 0.654902   0.58431375]\n",
      "   [0.7049632  0.6539828  0.58731616]]\n",
      "\n",
      "  [[0.8091299  0.75784314 0.69601715]\n",
      "   [0.82009804 0.76911765 0.7058824 ]\n",
      "   [0.8196691  0.76868874 0.7020221 ]\n",
      "   ...\n",
      "   [0.69411767 0.6509804  0.5803922 ]\n",
      "   [0.69889706 0.654902   0.58474267]\n",
      "   [0.71256125 0.66158086 0.5949142 ]]\n",
      "\n",
      "  [[0.81911767 0.7642157  0.7132353 ]\n",
      "   [0.8231005  0.7721201  0.7088848 ]\n",
      "   [0.82009804 0.76911765 0.702451  ]\n",
      "   ...\n",
      "   [0.69797796 0.6548407  0.5842525 ]\n",
      "   [0.7063113  0.6553309  0.58866423]\n",
      "   [0.7140319  0.6630515  0.5914828 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02892157 0.02892157 0.03676471]\n",
      "   [0.01960784 0.01960784 0.02647059]\n",
      "   [0.02303922 0.02303922 0.02303922]\n",
      "   ...\n",
      "   [0.6431373  0.5764706  0.5137255 ]\n",
      "   [0.6426471  0.57598037 0.5132353 ]\n",
      "   [0.6392157  0.57254905 0.50686276]]\n",
      "\n",
      "  [[0.01795343 0.02481618 0.0213848 ]\n",
      "   [0.02009804 0.02696078 0.02352941]\n",
      "   [0.01960784 0.02745098 0.02352941]\n",
      "   ...\n",
      "   [0.63143384 0.5647672  0.49515933]\n",
      "   [0.6322917  0.565625   0.49503675]\n",
      "   [0.6317402  0.5696691  0.49754903]]\n",
      "\n",
      "  [[0.02058824 0.02352941 0.01715686]\n",
      "   [0.01568628 0.02352941 0.01960784]\n",
      "   [0.01685049 0.02469363 0.02077206]\n",
      "   ...\n",
      "   [0.6406863  0.57892156 0.5029412 ]\n",
      "   [0.6372549  0.5754902  0.502451  ]\n",
      "   [0.63400733 0.57365197 0.5026348 ]]]\n",
      "\n",
      "\n",
      " [[[0.09656863 0.07935049 0.08786765]\n",
      "   [0.11323529 0.10588235 0.10833333]\n",
      "   [0.14332108 0.13939951 0.13155638]\n",
      "   ...\n",
      "   [0.72726715 0.6684436  0.64099264]\n",
      "   [0.7264706  0.68578434 0.6509804 ]\n",
      "   [0.72855395 0.6819853  0.64822304]]\n",
      "\n",
      "  [[0.14001225 0.12334559 0.12775736]\n",
      "   [0.1526348  0.1382353  0.14074755]\n",
      "   [0.16035539 0.15643382 0.14859068]\n",
      "   ...\n",
      "   [0.72843134 0.67401963 0.6387255 ]\n",
      "   [0.72585785 0.67487746 0.63958335]\n",
      "   [0.72046566 0.6730392  0.6358456 ]]\n",
      "\n",
      "  [[0.1723652  0.14883578 0.15667892]\n",
      "   [0.16323529 0.14754902 0.1504902 ]\n",
      "   [0.15637255 0.14068627 0.1367647 ]\n",
      "   ...\n",
      "   [0.7240196  0.67696077 0.62990195]\n",
      "   [0.7318627  0.6848039  0.6377451 ]\n",
      "   [0.73039216 0.6784314  0.6338235 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.46666667 0.43137255 0.37254903]\n",
      "   [0.46182597 0.42653185 0.36770833]\n",
      "   [0.45876226 0.42346814 0.36464462]\n",
      "   ...\n",
      "   [0.7759804  0.7132353  0.6504902 ]\n",
      "   [0.78339463 0.7206495  0.6579044 ]\n",
      "   [0.7683211  0.7173407  0.653125  ]]\n",
      "\n",
      "  [[0.46292892 0.4173407  0.36194852]\n",
      "   [0.45784312 0.4122549  0.35686275]\n",
      "   [0.46519607 0.41960785 0.36421567]\n",
      "   ...\n",
      "   [0.7617647  0.70931375 0.6431373 ]\n",
      "   [0.7651348  0.7141544  0.64748776]\n",
      "   [0.7622549  0.7112745  0.6483456 ]]\n",
      "\n",
      "  [[0.4715686  0.42604166 0.36133578]\n",
      "   [0.46519607 0.41813725 0.35833332]\n",
      "   [0.4617647  0.4122549  0.35245097]\n",
      "   ...\n",
      "   [0.766299   0.7153186  0.6408088 ]\n",
      "   [0.76666665 0.7173407  0.65177697]\n",
      "   [0.76476717 0.7137255  0.6574142 ]]]\n",
      "\n",
      "\n",
      " [[[0.8401348  0.79699755 0.7264093 ]\n",
      "   [0.83792895 0.79479164 0.7242034 ]\n",
      "   [0.8352941  0.7921569  0.72156864]\n",
      "   ...\n",
      "   [0.56078434 0.5058824  0.47058824]\n",
      "   [0.55       0.49981618 0.46029413]\n",
      "   [0.5469363  0.49987745 0.45281863]]\n",
      "\n",
      "  [[0.84313726 0.8        0.72156864]\n",
      "   [0.8387255  0.79558825 0.7240196 ]\n",
      "   [0.8397059  0.79656863 0.71813726]\n",
      "   ...\n",
      "   [0.5572917  0.5023897  0.45925245]\n",
      "   [0.5608456  0.51280636 0.46623775]\n",
      "   [0.5588235  0.5117647  0.4598039 ]]\n",
      "\n",
      "  [[0.8398897  0.79675245 0.7183211 ]\n",
      "   [0.84319854 0.8000613  0.7226103 ]\n",
      "   [0.84313726 0.8        0.7294118 ]\n",
      "   ...\n",
      "   [0.5495098  0.49460784 0.45147058]\n",
      "   [0.5564338  0.509375   0.4623162 ]\n",
      "   [0.5488358  0.50177693 0.45471814]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8326593  0.77775735 0.72677696]\n",
      "   [0.8352941  0.78431374 0.72156864]\n",
      "   [0.8426471  0.7916667  0.7289216 ]\n",
      "   ...\n",
      "   [0.76795346 0.7130515  0.6071691 ]\n",
      "   [0.7726103  0.7280024  0.6186887 ]\n",
      "   [0.76715684 0.720098   0.6230392 ]]\n",
      "\n",
      "  [[0.82990193 0.775      0.7240196 ]\n",
      "   [0.8353554  0.784375   0.7216299 ]\n",
      "   [0.83621323 0.78523284 0.72248775]\n",
      "   ...\n",
      "   [0.83480394 0.7882353  0.6852941 ]\n",
      "   [0.8495098  0.80851716 0.70343137]\n",
      "   [0.8408088  0.80061275 0.70012254]]\n",
      "\n",
      "  [[0.8273897  0.7773897  0.71905637]\n",
      "   [0.8297794  0.77634805 0.7209559 ]\n",
      "   [0.8291054  0.778125   0.7153799 ]\n",
      "   ...\n",
      "   [0.84430146 0.80018383 0.70165443]\n",
      "   [0.8497549  0.80992645 0.7092525 ]\n",
      "   [0.85729164 0.8165441  0.72199756]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.66476715 0.6005515  0.5367034 ]\n",
      "   [0.66746324 0.60355395 0.5369485 ]\n",
      "   [0.65177697 0.59001225 0.516973  ]\n",
      "   ...\n",
      "   [0.6859069  0.6349265  0.56041664]\n",
      "   [0.71501225 0.66403186 0.5973652 ]\n",
      "   [0.7014706  0.6504902  0.5853554 ]]\n",
      "\n",
      "  [[0.6542279  0.58756125 0.5091299 ]\n",
      "   [0.6608456  0.59460783 0.5148897 ]\n",
      "   [0.6396446  0.57297796 0.49454656]\n",
      "   ...\n",
      "   [0.69938725 0.6405637  0.5660539 ]\n",
      "   [0.69797796 0.63915443 0.56464463]\n",
      "   [0.7066789  0.6478554  0.5733456 ]]\n",
      "\n",
      "  [[0.6501838  0.5874387  0.49724266]\n",
      "   [0.63192403 0.56917894 0.47898284]\n",
      "   [0.6431373  0.5764706  0.49803922]\n",
      "   ...\n",
      "   [0.7068015  0.64797795 0.565625  ]\n",
      "   [0.69797796 0.63915443 0.5568015 ]\n",
      "   [0.6967524  0.6379289  0.5604779 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8091299  0.75030637 0.6365809 ]\n",
      "   [0.7824142  0.7235907  0.6098652 ]\n",
      "   [0.766973   0.7007353  0.5818015 ]\n",
      "   ...\n",
      "   [0.95735294 0.89460784 0.7651961 ]\n",
      "   [0.95343137 0.9014706  0.76862746]\n",
      "   [0.9452206  0.89865196 0.76384807]]\n",
      "\n",
      "  [[0.7852941  0.7406863  0.6166667 ]\n",
      "   [0.7802696  0.72745097 0.6038603 ]\n",
      "   [0.7856005  0.7262255  0.5978554 ]\n",
      "   ...\n",
      "   [0.95300245 0.9010417  0.77506125]\n",
      "   [0.9495711  0.89846814 0.77205884]\n",
      "   [0.95079654 0.8960784  0.77156866]]\n",
      "\n",
      "  [[0.7807598  0.7327206  0.6041667 ]\n",
      "   [0.77371323 0.7223652  0.59705883]\n",
      "   [0.77610296 0.71642154 0.58229166]\n",
      "   ...\n",
      "   [0.9511642  0.89528185 0.77224267]\n",
      "   [0.9472426  0.8913603  0.7683211 ]\n",
      "   [0.9523897  0.8935662  0.7719976 ]]]\n",
      "\n",
      "\n",
      " [[[0.63327205 0.59405637 0.5518995 ]\n",
      "   [0.6240196  0.5851103  0.5371324 ]\n",
      "   [0.63284314 0.597549   0.5387255 ]\n",
      "   ...\n",
      "   [0.6478554  0.60422796 0.5704044 ]\n",
      "   [0.6463848  0.60275733 0.5651961 ]\n",
      "   [0.6530637  0.60637254 0.5637255 ]]\n",
      "\n",
      "  [[0.6286152  0.5893995  0.55018383]\n",
      "   [0.6245711  0.5853554  0.54515934]\n",
      "   [0.6476103  0.6083946  0.5613358 ]\n",
      "   ...\n",
      "   [0.6471201  0.5951593  0.5652574 ]\n",
      "   [0.6579044  0.6059436  0.57506126]\n",
      "   [0.6408088  0.5894608  0.5545343 ]]\n",
      "\n",
      "  [[0.6449142  0.6056985  0.56648284]\n",
      "   [0.6314951  0.59227943 0.55306375]\n",
      "   [0.65882355 0.6117647  0.5647059 ]\n",
      "   ...\n",
      "   [0.6471201  0.5882966  0.56868875]\n",
      "   [0.63284314 0.5740196  0.547549  ]\n",
      "   [0.6338848  0.5799632  0.5500613 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11776961 0.14129902 0.13345589]\n",
      "   [0.12892157 0.15245098 0.15245098]\n",
      "   [0.12101716 0.14454657 0.14454657]\n",
      "   ...\n",
      "   [0.36164215 0.3416054  0.33069852]\n",
      "   [0.4430147  0.41507354 0.3930147 ]\n",
      "   [0.5292279  0.49148285 0.45655638]]\n",
      "\n",
      "  [[0.10980392 0.1264706  0.12205882]\n",
      "   [0.11531863 0.13198529 0.12757353]\n",
      "   [0.1060049  0.12169117 0.11776961]\n",
      "   ...\n",
      "   [0.2925858  0.27291667 0.28719363]\n",
      "   [0.27291667 0.25134805 0.24154411]\n",
      "   [0.40189952 0.36954656 0.34356618]]\n",
      "\n",
      "  [[0.11617647 0.12843138 0.11519608]\n",
      "   [0.13578431 0.14785539 0.13517156]\n",
      "   [0.13265932 0.14050245 0.13658088]\n",
      "   ...\n",
      "   [0.24877451 0.24338235 0.2629902 ]\n",
      "   [0.25220588 0.23713236 0.24105392]\n",
      "   [0.31280637 0.28584558 0.27408087]]]\n",
      "\n",
      "\n",
      " [[[0.9520221  0.82898283 0.86476713]\n",
      "   [0.9571691  0.8316789  0.8748162 ]\n",
      "   [0.9622549  0.8367647  0.87990195]\n",
      "   ...\n",
      "   [0.7862745  0.65392154 0.6813725 ]\n",
      "   [0.78137255 0.6490196  0.6764706 ]\n",
      "   [0.77953434 0.64411765 0.67156863]]\n",
      "\n",
      "  [[0.9590074  0.83253676 0.88400733]\n",
      "   [0.97003675 0.84270835 0.89460784]\n",
      "   [0.97653186 0.8471201  0.89025736]\n",
      "   ...\n",
      "   [0.80833334 0.6696078  0.6990196 ]\n",
      "   [0.8014706  0.65931374 0.6990196 ]\n",
      "   [0.7786152  0.6370711  0.6813725 ]]\n",
      "\n",
      "  [[0.9643995  0.8310662  0.88596815]\n",
      "   [0.96427697 0.831924   0.8863358 ]\n",
      "   [0.9617034  0.83621323 0.8793505 ]\n",
      "   ...\n",
      "   [0.7970588  0.6480392  0.6911765 ]\n",
      "   [0.8030025  0.6539828  0.6971201 ]\n",
      "   [0.79381126 0.65226716 0.6995098 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15845588 0.08394608 0.20159313]\n",
      "   [0.1367647  0.05833333 0.16813725]\n",
      "   [0.14105392 0.06262255 0.17242648]\n",
      "   ...\n",
      "   [0.6539828  0.5284926  0.58731616]\n",
      "   [0.64362746 0.5147059  0.5803922 ]\n",
      "   [0.6310662  0.5041054  0.5658701 ]]\n",
      "\n",
      "  [[0.14914216 0.07463235 0.19227941]\n",
      "   [0.14405638 0.065625   0.17542893]\n",
      "   [0.13817401 0.05974265 0.16954657]\n",
      "   ...\n",
      "   [0.6362745  0.51862746 0.5588235 ]\n",
      "   [0.6510417  0.5294118  0.5869485 ]\n",
      "   [0.6207108  0.49914217 0.5581495 ]]\n",
      "\n",
      "  [[0.15318628 0.07377451 0.19093138]\n",
      "   [0.1392157  0.05833333 0.1754902 ]\n",
      "   [0.14381127 0.06145833 0.18302695]\n",
      "   ...\n",
      "   [0.6137255  0.5026348  0.5264706 ]\n",
      "   [0.61764705 0.503125   0.5441176 ]\n",
      "   [0.62322307 0.5112745  0.5525122 ]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=uint8),\n",
       " array([[0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.977 , 0.    , 1.    , 0.5684],\n",
       "        [0.    , 0.0767, 0.3533, 0.707 ],\n",
       "        [0.    , 0.    , 0.1066, 0.83  ],\n",
       "        [0.    , 0.1925, 0.1703, 1.    ],\n",
       "        [0.    , 0.391 , 0.472 , 1.    ],\n",
       "        [0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.717 , 0.4822, 1.    , 1.    ]], dtype=float16))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.c Combine the data\n",
    "aug_data = {}\n",
    "for type in data_types:\n",
    "    data = tf.data.Dataset.zip((aug_images[type], aug_labels[type]))\n",
    "    if (type == 'train'):\n",
    "        data = data.shuffle(5000)\n",
    "    elif (type == 'test'):\n",
    "        data = data.shuffle(1000)\n",
    "    else:\n",
    "        data = data.shuffle(1000)\n",
    "    data = data.batch(8)    \n",
    "    data = data.prefetch(4)  # improve latency and throughput\n",
    "    aug_data[type] = data\n",
    "\n",
    "print(aug_data['test'].as_numpy_iterator().next()[0])    # images\n",
    "aug_data['test'].as_numpy_iterator().next()[1]           # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e498ab-0033-486f-8453-f5759935b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 - Building Deep Learning Model with Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3a274b-b150-4f84-8b69-0d22a866416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b598f5-4fd8-4574-9471-0236ede9ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f6f0ff2-52d1-43ba-aab8-2759e16b8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f84a997-e1e3-47ef-8517-a9f8bad7b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model function\n",
    "def create_model():\n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "\n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "\n",
    "    # Classification Model\n",
    "    class0 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(class0)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "\n",
    "    # Regression (Bounding Box) Model\n",
    "    reg0 = GlobalMaxPooling2D()(vgg)\n",
    "    reg1 = Dense(2048, activation='relu')(reg0)\n",
    "    reg2 = Dense(4, activation='sigmoid')(reg1)\n",
    "\n",
    "    facetracker = Model(inputs=input_layer, outputs=[class2, reg2])\n",
    "    return facetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6052ea0a-90de-4d88-b271-e5c32b38bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 120, 120, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, None, None, 512)      1471468   ['input_2[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " global_max_pooling2d (Glob  (None, 512)                  0         ['vgg16[0][0]']               \n",
      " alMaxPooling2D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Gl  (None, 512)                  0         ['vgg16[0][0]']               \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2048)                 1050624   ['global_max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 2048)                 1050624   ['global_max_pooling2d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    8196      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16826181 (64.19 MB)\n",
      "Trainable params: 16826181 (64.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "facetracker = create_model()\n",
    "facetracker.summary()\n",
    "keras.utils.plot_model(facetracker, \"initial model\", show_shapes=True, show_layer_names=True, show_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c899805b-4e51-4c49-abe1-2781eca45dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 120, 120, 3)\n",
      "1/1 [==============================] - 1s 937ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.5195978 ],\n",
       "        [0.5889544 ],\n",
       "        [0.5825449 ],\n",
       "        [0.62903005],\n",
       "        [0.45246664],\n",
       "        [0.56652933],\n",
       "        [0.5924776 ],\n",
       "        [0.55499333]], dtype=float32),\n",
       " array([[0.41382602, 0.43507943, 0.35255468, 0.6840632 ],\n",
       "        [0.34845304, 0.45146948, 0.3919316 , 0.6254567 ],\n",
       "        [0.40200987, 0.35000685, 0.36320502, 0.6969399 ],\n",
       "        [0.4727461 , 0.3934826 , 0.30914906, 0.66708475],\n",
       "        [0.41071898, 0.4226405 , 0.45249328, 0.6815185 ],\n",
       "        [0.4295434 , 0.42590398, 0.405505  , 0.6759449 ],\n",
       "        [0.41726786, 0.39431426, 0.4065091 , 0.7552469 ],\n",
       "        [0.45479757, 0.38928175, 0.41880015, 0.61845714]], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting without training\n",
    "x, y = aug_data['train'].as_numpy_iterator().next()\n",
    "print(x.shape)\n",
    "classes, coords = facetracker.predict(x)\n",
    "classes, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1b1a3ed-5539-452d-a49b-bf296e8776d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 - Losses & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "490eec4e-b5b0-4b26-a2ab-4b28a89c2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "batches_per_epoch = len(aug_data['train'])\n",
    "decay = (1./0.75 -1)/batches_per_epoch\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f409b61-4216-4882-bc67-fce7c4df8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(act, pred):\n",
    "    delta_coord = tf.reduce_sum(tf.square(act[:,:2] - pred[:,:2]))\n",
    "\n",
    "    h_act = act[:,3] - act[:,1]\n",
    "    w_act = act[:,2] - act[:,0]\n",
    "    h_pred = pred[:,3] - pred[:,1]\n",
    "    w_pred = pred[:,2] - pred[:,0]\n",
    "    delta_size = tf.reduce_sum(tf.square(w_act - w_pred) + tf.square(h_act - h_pred))\n",
    "\n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1784eb0b-d808-4a4d-a610-67cc6266ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss = localization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb51338f-e1a9-40be-ac9d-71ce576e4cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.1566067>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Loss on a sample\n",
    "localization_loss(y[1], coords)\n",
    "classloss(y[0], classes)\n",
    "regressloss(y[1], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baa5918-cc77-4fd6-9e66-f9a1c2e6fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31e761ae-d56e-43f6-8cb6-02c1c0d59cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.a - class\n",
    "class FaceTracker(Model):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.classloss = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "\n",
    "    def train_step(self, batch, **kwargs):\n",
    "        images, labels = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, coords = self.model(images, training=True)\n",
    "            \n",
    "            batch_classloss = self.classloss(labels[0], classes)\n",
    "            batch_lloss = self.lloss(tf.cast(labels[1], tf.float32), coords)\n",
    "            \n",
    "            total_loss = batch_lloss+0.5*batch_classloss\n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables) #\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables)) #\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_lloss}\n",
    "\n",
    "    def test_step(self, batch, **kwargs):\n",
    "        images, labels = batch\n",
    "        classes, coords = self.model(images, training=False)\n",
    "\n",
    "        batch_classloss = self.classloss(labels[0], classes)\n",
    "        batch_lloss = self.lloss(tf.cast(labels[1], tf.float32), coords)\n",
    "        total_loss = batch_lloss+0.5*batch_classloss\n",
    "\n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_lloss}\n",
    "\n",
    "    def call(self, images, **kwargs):\n",
    "        return self.model(images, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fb9bf85-e762-4072-9b11-66efa00f9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceTracker(facetracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4961fe7-9dc3-4321-b4a6-947331d89200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c262e4f-84a7-4a92-9b6a-1c0167e33289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 194s 2s/step - total_loss: 1.6078 - class_loss: 0.3930 - regress_loss: 1.4113 - val_total_loss: 0.7582 - val_class_loss: 0.6970 - val_regress_loss: 0.4097\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 179s 2s/step - total_loss: 0.9927 - class_loss: 0.3041 - regress_loss: 0.8406 - val_total_loss: 0.0800 - val_class_loss: 0.0469 - val_regress_loss: 0.0565\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 168s 2s/step - total_loss: 0.6553 - class_loss: 0.2120 - regress_loss: 0.5492 - val_total_loss: 1.1860 - val_class_loss: 0.6407 - val_regress_loss: 0.8656\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 203s 2s/step - total_loss: 0.5907 - class_loss: 0.1713 - regress_loss: 0.5051 - val_total_loss: 0.0998 - val_class_loss: 0.0520 - val_regress_loss: 0.0738\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 179s 2s/step - total_loss: 0.5123 - class_loss: 0.1612 - regress_loss: 0.4317 - val_total_loss: 0.0401 - val_class_loss: 0.0281 - val_regress_loss: 0.0261\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 187s 2s/step - total_loss: 0.5494 - class_loss: 0.1619 - regress_loss: 0.4685 - val_total_loss: 0.2060 - val_class_loss: 0.0750 - val_regress_loss: 0.1685\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 194s 2s/step - total_loss: 0.4400 - class_loss: 0.1370 - regress_loss: 0.3715 - val_total_loss: 0.0267 - val_class_loss: 0.0155 - val_regress_loss: 0.0189\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 212s 2s/step - total_loss: 0.4699 - class_loss: 0.1523 - regress_loss: 0.3938 - val_total_loss: 0.0480 - val_class_loss: 0.0022 - val_regress_loss: 0.0469\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 203s 2s/step - total_loss: 0.5051 - class_loss: 0.1515 - regress_loss: 0.4294 - val_total_loss: 1.1603 - val_class_loss: 0.9973 - val_regress_loss: 0.6616\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 203s 2s/step - total_loss: 0.5211 - class_loss: 0.1488 - regress_loss: 0.4467 - val_total_loss: 1.0043 - val_class_loss: 0.0909 - val_regress_loss: 0.9589\n"
     ]
    }
   ],
   "source": [
    "# 7.b Train\n",
    "logdir='logs'\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(aug_data['train'].take(100), epochs=10, \n",
    "                    validation_data=aug_data['val'], callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0992d64-fab2-45fc-bac1-0b535d623689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade2fff-38d3-4d17-9b60-bee498985d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a2f4ee8-3178-4463-861b-042db57cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 460ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.94338655],\n",
       "        [0.03185209],\n",
       "        [0.9999999 ],\n",
       "        [0.03022125],\n",
       "        [0.50843704],\n",
       "        [0.99999976],\n",
       "        [0.15136749],\n",
       "        [0.11426912]], dtype=float32),\n",
       " array([[0.17687875, 0.05481217, 0.7464975 , 0.68787485],\n",
       "        [0.02564882, 0.02330072, 0.0300895 , 0.03386927],\n",
       "        [0.3542798 , 0.10361259, 0.9563853 , 0.9033525 ],\n",
       "        [0.02750944, 0.01476298, 0.02891585, 0.03980681],\n",
       "        [0.03675908, 0.03087154, 0.4159087 , 0.52682054],\n",
       "        [0.14307618, 0.2404233 , 0.7453403 , 0.919243  ],\n",
       "        [0.09227018, 0.03287106, 0.09265514, 0.10350192],\n",
       "        [0.07772366, 0.04728038, 0.08805643, 0.10673418]], dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = aug_data['test'].as_numpy_iterator()\n",
    "test_sample = test_data.next()\n",
    "prediction = facetracker.predict(test_sample[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028654e-7849-435d-8ad5-2aef99a14256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = prediction[1][idx]\n",
    "    \n",
    "    if prediction[0][idx] > 0.9:\n",
    "        cv2.rectangle(sample_image, \n",
    "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7a3ed80-40df-4c98-bbf3-9853222c02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "facetracker.save('facedetection.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54447f55-afe8-4602-9ae7-f34a60d6b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "facetracker = load_model('facedetection.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b34bb-3aa2-4f5b-874f-2e8cceba4066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Live Test \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    retval, frame = cap.read() # returns a boolean, and captured frame which is a numpy array\n",
    "    frame = frame[50:500, 50:500,:] \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(frame_rgb, (120,120))\n",
    "\n",
    "    pred = facetracker.predict(np.expand_dims(resized/255, 0))\n",
    "    sample_coords = pred[1][0]\n",
    "\n",
    "    if pred[0] > 0.5:\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        # Text\n",
    "        cv2.putText(frame, 'face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
